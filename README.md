
# ğŸ” Log Analyzer & Q&A App (Streamlit + LangChain + Ollama)

This app analyzes log files or answers user questions using LLMs. It supports both **OpenAI (cloud)** and **Ollama (local)** for private, offline log analysis.

---

## ğŸš€ Features

- ğŸ“¤ Upload `.log` or `.txt` files
- ğŸ§  Summarize logs or answer tech questions
- ğŸŒ Supports OpenAI + ğŸ–¥ï¸ Ollama (local LLMs like llama3)

---

## ğŸ› ï¸ Setup

### 1ï¸âƒ£ Create virtual environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ’» Using Local LLM (Ollama + llama3)

1. Install Ollama: https://ollama.com/download

2. Pull the model:

```bash
ollama pull llama3
```

3. Run the local app:

```bash
streamlit run app-ollama.py
```

> âœ… No OpenAI key required. Everything runs locally using your CPU/RAM.

---

## ğŸ“„ Example Log Input

```log
[ERROR] nginx failed to bind to port 80
[INFO] nginx restarted
[ERROR] Port already in use
```

---

## ğŸ“ Project Structure

```
log-analyzer/
â”œâ”€â”€ app.py              # OpenAI version
â”œâ”€â”€ app-ollama.py       # Local LLM (Ollama) version
â”œâ”€â”€ .env.example        # For OpenAI use
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ“œ License

MIT License
